{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrmZ25oKMQdQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import cv2\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import argparse\n",
        "\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-v\", \"--VIDEO_DIR\", required=True, help=\"path to the directory containing the videos\")\n",
        "ap.add_argument(\"-o\", \"--OUTPUT_DIR\", required=True, help=\"path to the output directory\")\n",
        "ap.add_argument(\"-n\", \"--MAX_WORKERS\", default=os.cpu_count(), type=int,\n",
        "                help=\"number of processes to use for processing the videos\")\n",
        "args = vars(ap.parse_args())\n",
        "\n",
        "if not os.path.exists(args[\"OUTPUT_DIR\"]):\n",
        "    os.makedirs(args[\"OUTPUT_DIR\"])\n",
        "\n",
        "def process_video(video_file):\n",
        "    # Load the video file\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Create output directory for the video\n",
        "    video_name = os.path.splitext(os.path.basename(video_file))[0]\n",
        "    video_output_dir = os.path.join(args[\"OUTPUT_DIR\"], video_name)\n",
        "    os.makedirs(video_output_dir, exist_ok=True)\n",
        "\n",
        "    # Create output data file for the video\n",
        "    data_file = os.path.join(video_output_dir, f\"{video_name}.csv\")\n",
        "\n",
        "    # Open CSV file for writing\n",
        "    with open(data_file, mode='w') as csv_file:\n",
        "        fieldnames = ['frame', 'person', 'x', 'y', 'w', 'h']\n",
        "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        # Process each frame in the video\n",
        "        for i in range(frame_count):\n",
        "            # Read the frame\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Apply person detection algorithm to the frame\n",
        "            # You can use any pre-trained object detection model in OpenCV here\n",
        "            # Here's an example using the Haar cascades classifier for detecting pedestrians\n",
        "            classifier = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_fullbody.xml\")\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            detections = classifier.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=2)\n",
        "\n",
        "            # If people are detected in the frame, save the frame and its data\n",
        "            if len(detections) > 0:\n",
        "                frame_file = os.path.join(video_output_dir, f\"{i:04d}.jpg\")\n",
        "                cv2.imwrite(frame_file, frame)\n",
        "\n",
        "                # Save the frame data in the output data file\n",
        "                for j, (x, y, w, h) in enumerate(detections):\n",
        "                    writer.writerow({\n",
        "                        \"frame\": i,\n",
        "                        \"person\": j,\n",
        "                        \"x\": x,\n",
        "                        \"y\": y,\n",
        "                        \"w\": w,\n",
        "                        \"h\": h\n",
        "                    })\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "def process_videos():\n",
        "    video_files = [os.path.join(args[\"VIDEO_DIR\"], f) for f in os.listdir(args[\"VIDEO_DIR\"]) if f.endswith(\".mp4\")]\n",
        "\n",
        "    # Create a thread pool executor with a maximum number of worker threads\n",
        "    with ThreadPoolExecutor(max_workers=args[\"MAX_WORKERS\"]) as executor:\n",
        "        # Submit the video processing tasks to the thread pool\n",
        "        futures = [executor.submit(process_video, video_file) for video_file in video_files]\n",
        "\n",
        "        # Wait for all tasks to complete\n",
        "        for future in futures:\n",
        "            future.result()\n",
        "\n",
        "process_videos()\n"
      ]
    }
  ]
}